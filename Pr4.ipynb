{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shradhadabhade/AIES/blob/main/Pr4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqVFgveyL1mQ",
        "outputId": "82d95174-2afe-477c-c4eb-eaef23a21070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc: 0.9833333333333333\n",
            "Permutation importances (top 5):\n",
            "f7    0.207222\n",
            "f0    0.163889\n",
            "f4    0.067778\n",
            "f5    0.059167\n",
            "f3    0.037500\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# problem4_permutation_importance.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_classification(n_samples=600, n_features=8, n_informative=4, random_state=0)\n",
        "feature_names = [f\"f{i}\" for i in range(X.shape[1])]\n",
        "X = pd.DataFrame(X, columns=feature_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "print(\"Test acc:\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "r = permutation_importance(clf, X_test, y_test, n_repeats=20, random_state=0)\n",
        "importances = pd.Series(r.importances_mean, index=feature_names).sort_values(ascending=False)\n",
        "print(\"Permutation importances (top 5):\")\n",
        "print(importances.head(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "\n",
        "**Model Accuracy**\n",
        "\n",
        "The model achieved a test accuracy of ~98.3%, which means the classifier is performing very well on new/unseen data.\n",
        "\n",
        "**Purpose of PFI (Permutation Feature Importance)**\n",
        "\n",
        "PFI helps us understand which features contribute the most to the model’s decisions.\n",
        "\n",
        "It works by randomly shuffling each feature one at a time and measuring how much the model performance drops.\n",
        "\n",
        "If shuffling a feature causes a big drop in accuracy, that feature is important.\n",
        "\n",
        "If the accuracy doesn't change much, that feature has little influence.\n",
        "\n",
        "**Interpreting the values**\n",
        "\n",
        "The numeric values represent the decrease in performance (on average) when that feature is permuted.\n",
        "\n",
        "**Result Interpretation:**\n",
        "\n",
        "Feature\tImportance\tMeaning\n",
        "f7 (0.207)\thighest impact\tShuffling f7 caused 20% performance drop → f7 is the most influential feature.\n",
        "f0 (0.164)\tsecond most important\tShuffling f0 decreases model accuracy significantly → strong predictor.\n",
        "f4 & f5 (0.06–0.07)\tmoderate importance\tThese features contribute but less than f7/f0.\n",
        "f3 (~0.038)\tsmall influence\tLower impact on prediction.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "“From the PFI results, features f7 and f0 are the most important since permuting them decreases the model’s prediction accuracy the most. This means the model mainly relies on these features for classification. Features like f4, f5, and f3 contribute less, and therefore have lower importance scores.”"
      ],
      "metadata": {
        "id": "Ai7r3iUfSSZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question\tExpected Answer**\n",
        "1. What does the test accuracy value indicate?\n",
        "\n",
        "It tells how well the trained model performs on unseen data. A score of 0.98 means 98% predictions on the test set were correct.\n",
        "\n",
        "2. What is Permutation Feature Importance (PFI)?\n",
        "\n",
        "PFI measures how the model’s performance changes when the values of one feature are randomly shuffled. If performance drops a lot, the feature is important.\n",
        "\n",
        "3. Why do we shuffle one feature at a time?\n",
        "\n",
        "\tTo isolate the effect of that particular feature while keeping the rest of the model inputs unchanged.\n",
        "4. What does a higher importance score (like for f7) mean?\n",
        "\n",
        "\tIt means shuffling f7 caused the largest drop in model accuracy; hence f7 contributes most to prediction.\n",
        "5. Why is PFI considered model-agnostic?\n",
        "\n",
        "\tIt does not depend on how the model was built; it only analyzes the model’s output predictions.\n",
        "6. Can PFI handle both regression and classification models?\n",
        "\n",
        "Yes, the concept remains the same — measure drop in model performance after permutation.\n",
        "7. Why is feature f3 less important than f7 in the output?\n",
        "\n",
        "Because permuting f3 caused a smaller decrease in accuracy compared to f7, meaning f3 influences predictions less.\n",
        "8. What is the advantage of PFI over built-in feature importance of tree models?\n",
        "\n",
        "\tPFI reflects importance relative to the actual predictive performance, not internal model structure"
      ],
      "metadata": {
        "id": "nVLZew4sT6wE"
      }
    }
  ]
}